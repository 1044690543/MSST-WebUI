{
    "成功将端口设置为": "text1",
    "[INFO]正在初始化版本配置文件": "text2",
    "[INFO]检测到": "text3",
    "旧版配置, 正在更新至最新版": "text4",
    "[INFO]正在初始化configs目录": "text5",
    "[INFO]正在初始化configs_template目录": "text6",
    "[INFO]正在初始化data目录": "text7",
    "[INFO]正在初始化pretrain目录": "text8",
    "[INFO]设备信息：": "text9",
    "使用MPS": "text10",
    "无可用的加速设备, 使用CPU": "text11",
    "设备检查失败": "text12",
    "错误: 无法找到增强配置文件模板, 请检查文件configs_template/augmentations_template.yaml是否存在。": "text13",
    "模型不存在!": "text15",
    "无预设": "text16",
    "请先选择文件夹!": "text17",
    "配置保存成功!": "text35",
    "配置保存失败!": "text19",
    "设置保存成功! 请重启WebUI以应用。": "text20",
    "设置重置成功, 请重启WebUI刷新! ": "text21",
    "设置重置失败!": "text22",
    "记录重置成功, 请重启WebUI刷新! ": "text23",
    "记录重置失败!": "text24",
    "仅输出主音轨": "text27",
    "仅输出次音轨": "text28",
    "请先选择模型保存路径! ": "text29",
    "初始模型": "text345",
    "该模型不支持修改此值": "text33",
    "normalize (该模型不支持修改此值) ": "text34",
    "配置重置成功!": "text36",
    "备份配置文件不存在!": "text37",
    "请上传一个音频文件。": "text38",
    "处理完成! 分离完成的音频文件已保存在": "text82",
    "GPU ID格式错误, 请重新输入": "text41",
    "请选择模型": "text49",
    "请选择输入目录": "text43",
    "处理失败!": "text95",
    "请上传一个音频文件": "text77",
    "请选择输出目录": "text50",
    "请选择输入文件夹": "text48",
    "处理完成, 结果已保存至": "text51",
    "选择模型": "text303",
    "输出音轨": "text239",
    "请填写预设名称": "text57",
    "请选择预设": "text247",
    "预设": "text78",
    "保存成功": "text61",
    "预设不存在": "text76",
    "删除成功": "text69",
    "预设已删除": "text75",
    "不存在": "text127",
    "模型": "text126",
    "请上传至少一个文件": "text83",
    "所有文件转换失败, 请检查文件格式和ffmpeg路径。": "text84",
    "处理完成, 文件已保存为: ": "text94",
    "请上传至少2个文件": "text88",
    "上传的文件数目与权重数目不匹配": "text89",
    "请先下载SOME预处理模型并放置在tools/SOME_weights文件夹下! ": "text92",
    "请上传wav格式文件": "text93",
    "请选择模型类型": "text117",
    "已安装": "text123",
    "模型类型": "text124",
    "链接无效": "text108",
    "下载中": "text112",
    "下载成功": "text114",
    "下载失败": "text116",
    "已打开": "text128",
    "的下载链接": "text129",
    "模型类型错误, 请重新选择": "text139",
    "配置文件不存在, 请重新选择": "text140",
    "数据集路径不存在, 请重新选择": "text132",
    "验证集路径不存在, 请重新选择": "text142",
    "数据集类型错误, 请重新选择": "text134",
    "device_ids格式错误, 请重新输入": "text143",
    "模型保存路径不存在, 请重新选择": "text136",
    "请前往控制台查看报错信息! ": "text137",
    "训练启动失败!": "text138",
    "模型不存在, 请重新选择": "text141",
    "验证完成! 请打开输出文件夹查看详细结果": "text144",
    "验证失败!": "text145",
    "当前版本: ": "text398",
    ", 发现新版本: ": "text147",
    ", 已是最新版本": "text149",
    "检查更新失败": "text150",
    "暂无备份文件": "text153",
    "请选择备份文件": "text154",
    "已成功恢复备份": "text155",
    ", 请重启WebUI更新预设流程。": "text156",
    "已成功备份至": "text157",
    "选择需要恢复的预设流程备份": "text393",
    "仅供个人娱乐和非商业用途, 禁止用于血腥/暴力/性相关/政治相关内容。[点击前往教程文档](https://r1kc63iz15l.feishu.cn/wiki/JSp3wk7zuinvIXkIqSUcCXY1nKc)<br>本整合包完全免费, 严禁以任何形式倒卖, 如果你从任何地方**付费**购买了本整合包, 请**立即退款**。<br> 整合包作者: [bilibili@阿狸不吃隼舞](https://space.bilibili.com/403335715) [Github@KitsuneX07](https://github.com/KitsuneX07) | [Bilibili@Sucial](https://space.bilibili.com/445022409) [Github@SUC-DriverOld](https://github.com/SUC-DriverOld) | Gradio主题: [Gradio Theme](https://huggingface.co/spaces/NoCrypt/miku)": "text159",
    "MSST分离": "text160",
    "MSST音频分离原项目地址: [https://github.com/ZFTurbo/Music-Source-Separation-Training](https://github.com/ZFTurbo/Music-Source-Separation-Training)": "text161",
    "多卡用户请使用空格分隔GPU ID, 例如: ``0 1 2``。可前往设置页面查看显卡信息。": "text163",
    "选择使用的GPU ID": "text164",
    "使用CPU (注意: 使用CPU会导致速度非常慢) ": "text220",
    "同时输出次级音轨": "text241",
    "单个音频上传": "text222",
    "批量音频上传": "text223",
    "输入目录": "text265",
    "选择文件夹": "text390",
    "打开文件夹": "text364",
    "输出目录": "text362",
    "单个音频分离": "text230",
    "批量音频分离": "text231",
    "推理参数设置 (一般不需要动) ": "text178",
    "只有在点击保存后才会生效。参数直接写入配置文件, 无法撤销。假如不知道如何设置, 请保持默认值。<br>请牢记自己修改前的参数数值, 防止出现问题以后无法恢复。请确保输入正确的参数, 否则可能会导致模型无法正常运行。<br>假如修改后无法恢复, 请点击``重置``按钮, 这会使得配置文件恢复到默认值。": "text179",
    "请先选择模型": "text240",
    "batch_size: 批次大小, 一般不需要改": "text183",
    "dim_t: 时序维度大小, 一般不需要改 (部分模型没有此参数)": "text184",
    "num_overlap: 窗口重叠长度, 数值越小速度越快, 但会牺牲效果": "text185",
    "normalize: 是否对音频进行归一化处理 (部分模型没有此参数)": "text186",
    "重置配置": "text187",
    "保存配置": "text188",
    "UVR分离": "text189",
    "说明: 本整合包仅融合了UVR的VR Architecture模型, MDX23C和HtDemucs类模型可以直接使用前面的MSST音频分离。<br>使用UVR模型进行音频分离时, 若有可用的GPU, 软件将自动选择, 否则将使用CPU进行分离。<br>UVR分离使用项目: [https://github.com/nomadkaraoke/python-audio-separator](https://github.com/nomadkaraoke/python-audio-separator) 并进行了优化。": "text190",
    "Window Size: 窗口大小, 用于平衡速度和质量": "text192",
    "Aggression: 主干提取强度, 范围-100-100, 人声请选5": "text193",
    "输出格式": "text194",
    "使用CPU": "text195",
    "以下是一些高级设置, 一般保持默认即可": "text204",
    "Batch Size: 一次要处理的批次数, 越大占用越多RAM, 处理速度加快": "text205",
    "Normalization: 最大峰值振幅, 用于归一化输入和输出音频。取值为0-1": "text206",
    "Post Process Threshold: 后处理特征阈值, 取值为0.1-0.3": "text207",
    "Invert Spectrogram: 二级步骤将使用频谱图而非波形进行反转, 可能会提高质量, 但速度稍慢": "text208",
    "Enable TTA: 启用“测试时间增强”, 可能会提高质量, 但速度稍慢": "text209",
    "High End Process: 将输出音频缺失的频率范围镜像输出": "text210",
    "Enable Post Process: 识别人声输出中残留的人工痕迹, 可改善某些歌曲的分离效果": "text211",
    "Debug Mode: 启用调试模式, 向开发人员反馈时, 请开启此模式": "text212",
    "预设流程": "text243",
    "预设流程允许按照预设的顺序运行多个模型。每一个模型的输出将作为下一个模型的输入。": "text216",
    "使用预设": "text217",
    "该模式下的UVR推理参数将直接沿用UVR分离页面的推理参数, 如需修改请前往UVR分离页面。": "text218",
    "制作预设": "text232",
    "注意: MSST模型仅支持输出主要音轨, UVR模型支持自定义主要音轨输出。<br>同时输出次级音轨: 选择True将同时输出该次分离得到的次级音轨, **此音轨将直接保存至**输出目录下的secondary_output文件夹, **不会经过后续流程处理**<br>": "text233",
    "预设名称": "text234",
    "请输入预设名称": "text235",
    "选择模型类型": "text352",
    "请先选择模型类型": "text304",
    "添加至流程": "text242",
    "重新输入": "text244",
    "保存上述预设流程": "text245",
    "查看/删除预设": "text246",
    "`model_type`: 模型类型；`model_name`: 模型名称；`stem`: 主要输出音轨；<br>`secondary_output`: 同时输出次级音轨。选择True将同时输出该次分离得到的次级音轨, **此音轨将直接保存至**输出目录下的secondary_output文件夹, **不会经过后续流程处理**": "text248",
    "请先选择预设": "text252",
    "删除所选预设": "text253",
    "小工具": "text254",
    "音频格式转换": "text255",
    "上传一个或多个音频文件并将其转换为指定格式。<br>支持的格式包括 .mp3, .flac, .wav, .ogg, .m4a, .wma, .aac...等等。<br>**不支持**网易云音乐/QQ音乐等加密格式, 如.ncm, .qmc等。": "text256",
    "上传一个或多个音频文件": "text257",
    "选择或输入音频输出格式": "text258",
    "选择音频输出目录": "text259",
    "转换音频": "text262",
    "合并音频": "text271",
    "点击合并音频按钮后, 将自动把输入文件夹中的所有音频文件合并为一整个音频文件<br>目前支持的格式包括 .mp3, .flac, .wav, .ogg 这四种<br>合并后的音频会保存至输出目录中, 文件名为merged_audio.wav": "text264",
    "计算SDR": "text276",
    "上传两个**wav音频文件**并计算它们的[SDR](https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021#evaluation-metric)。<br>SDR是一个用于评估模型质量的数值。数值越大, 模型算法结果越好。": "text273",
    "原始音频": "text274",
    "分离后的音频": "text275",
    "Ensemble模式": "text277",
    "可用于集成不同算法的结果。具体的文档位于/docs/ensemble.md": "text278",
    "上传多个音频文件": "text279",
    "集成模式": "text280",
    "权重(以空格分隔, 数量要与上传的音频一致)": "text281",
    "运行": "text285",
    "### 集成模式": "text286",
    "1. `avg_wave`: 在1D变体上进行集成, 独立地找到波形的每个样本的平均值<br>2. `median_wave`: 在1D变体上进行集成, 独立地找到波形的每个样本的中位数<br>3. `min_wave`: 在1D变体上进行集成, 独立地找到波形的每个样本的最小绝对值<br>4. `max_wave`: 在1D变体上进行集成, 独立地找到波形的每个样本的最大绝对值<br>5. `avg_fft`: 在频谱图 (短时傅里叶变换 (STFT) 2D变体) 上进行集成, 独立地找到频谱图的每个像素的平均值。平均后使用逆STFT得到原始的1D波形<br>6. `median_fft`: 与avg_fft相同, 但使用中位数代替平均值 (仅在集成3个或更多来源时有用) <br>7. `min_fft`: 与avg_fft相同, 但使用最小函数代替平均值 (减少激进程度) <br>8. `max_fft`: 与avg_fft相同, 但使用最大函数代替平均值 (增加激进程度) ": "text287",
    "### 注意事项": "text313",
    "1. min_fft可用于进行更保守的合成, 它将减少更激进模型的影响。<br>2. 最好合成等质量的模型。在这种情况下, 它将带来增益。如果其中一个模型质量不好, 它将降低整体质量。<br>3. 在原仓库作者的实验中, 与其他方法相比, avg_wave在SDR分数上总是更好或相等。<br>4. 上传的文件名**不能包含空格**, 最终会在输出目录下生成一个`ensemble_<集成模式>.wav`。": "text289",
    "歌声转MIDI": "text290",
    "歌声转MIDI功能使用开源项目[SOME](https://github.com/openvpi/SOME/), 可以将分离得到的**干净的歌声**转换成.mid文件。<br>【必须】若想要使用此功能, 请先下载权重文件[model_steps_64000_simplified.ckpt](https://hf-mirror.com/Sucial/SOME_Models/resolve/main/model_steps_64000_simplified.ckpt)并将其放置在程序目录下的`tools/SOME_weights`文件夹内。文件命名不可随意更改! <br>【重要】只能上传wav格式的音频! ": "text291",
    "上传wav格式音频": "text292",
    "输入音频BPM": "text293",
    "开始转换": "text297",
    "1. 音频BPM (每分钟节拍数) 可以通过MixMeister BPM Analyzer等软件测量获取。<br>2. 为保证MIDI提取质量, 音频文件请采用干净清晰无混响底噪人声。<br>3. 输出MIDI不带歌词信息, 需要用户自行添加歌词。<br>4. 实际使用体验中部分音符会出现断开的现象, 需自行修正。SOME的模型主要面向DiffSinger唱法模型自动标注, 比正常用户在创作中需要的MIDI更加精细, 因而可能导致模型倾向于对音符进行切分。<br>5. 提取的MIDI没有量化/没有对齐节拍/不适配BPM, 需自行到各编辑器中手动调整。": "text299",
    "安装模型": "text300",
    "自动从Huggingface镜像站或Github下载模型。<br>若自动下载出现报错或下载过慢, 请点击手动下载, 跳转至下载链接。手动下载完成后, 请根据你选择的模型类型放置到对应文件夹内。": "text301",
    "### 当前UVR模型目录: ": "text305",
    ", 如需更改, 请前往设置页面。": "text306",
    "打开MSST模型目录": "text307",
    "打开UVR模型目录": "text308",
    "自动下载": "text309",
    "手动下载": "text310",
    "### 安装完成后, 请点击下方按钮重启WebUI": "text311",
    "重启WebUI": "text405",
    "1. MSST模型默认下载在pretrain/<模型类型>文件夹下。UVR模型默认下载在设置中的UVR模型目录中。<br>2. **请勿删除**UVR模型目录下的download_checks.json, mdx_model_data.json, vr_model_data.json这三个文件! <br>3. 下加载进度可以打开终端查看。如果一直卡着不动或者速度很慢, 在确信网络正常的情况下请尝试重启WebUI。<br>4. 若下载失败, 会在模型目录**留下一个损坏的模型**, 请**务必**打开模型目录手动删除! <br>5. 点击“重启WebUI”按钮后, 会短暂性的失去连接, 随后会自动开启一个新网页。": "text314",
    "### 下面是一些模型下载链接": "text315",
    "[Huggingface镜像站](https://hf-mirror.com/KitsuneX07/Music_Source_Sepetration_Models) | [Huggingface](https://huggingface.co/KitsuneX07/Music_Source_Sepetration_Models) | [UVR模型仓库地址](https://github.com/TRvlvr/model_repo/releases/tag/all_public_uvr_models)<br>你也可以在此整合包下载链接中的All_Models文件夹中找到所有可用的模型并下载。": "text316",
    "MSST训练": "text317",
    "此页面提供数据集制作教程, 训练参数选择, 以及一键训练。有关配置文件的修改和数据集文件夹的详细说明请参考MSST原项目: [https://github.com/ZFTurbo/Music-Source-Separation-Training](https://github.com/ZFTurbo/Music-Source-Separation-Training)<br>在开始下方的模型训练之前, 请先进行训练数据的制作。": "text318",
    "训练": "text319",
    "选择训练模型类型": "text320",
    "配置文件路径": "text353",
    "请输入配置文件路径或选择配置文件": "text354",
    "选择配置文件": "text355",
    "数据集类型": "text324",
    "数据集路径": "text325",
    "请输入或选择数据集文件夹": "text326",
    "选择数据集文件夹": "text327",
    "说明: 数据集类型即训练集制作Step 1中你选择的类型, 1: Type1; 2: Type2; 3: Type3; 4: Type4, 必须与你的数据集类型相匹配。": "text328",
    "验证集路径": "text359",
    "请输入或选择验证集文件夹": "text360",
    "选择验证集文件夹": "text361",
    "以下是一些训练参数的设置": "text332",
    "num_workers: 数据集读取线程数, 0为自动": "text333",
    "device_ids: 选择显卡, 多卡用户请使用空格分隔": "text334",
    "随机数种子, 0为随机": "text335",
    "是否将加载的数据放置在固定内存中, 默认为否": "text368",
    "是否使用MultiSTFT Loss, 默认为否": "text337",
    "是否使用MSE loss, 默认为否": "text338",
    "是否使用L1 loss, 默认为否": "text339",
    "模型保存路径": "text340",
    "请输入或选择模型保存文件夹": "text341",
    "说明: 继续训练或微调模型训练时, 请选择初始模型, 否则将从头开始训练! ": "text344",
    "刷新初始模型列表": "text346",
    "保存上述训练配置": "text347",
    "开始训练": "text348",
    "点击开始训练后, 请到终端查看训练进度或报错, 下方不会输出报错信息, 想要停止训练可以直接关闭终端。在训练过程中, 你也可以关闭网页, 仅**保留终端**。": "text349",
    "验证": "text350",
    "此页面用于手动验证模型效果, 测试验证集, 输出SDR测试信息。输出的信息会存放在输出文件夹的results.txt中。<br>下方参数将自动加载训练页面的参数, 在训练页面点击保存训练参数后, 重启WebUI即可自动加载。当然你也可以手动输入参数。<br>": "text351",
    "模型路径": "text356",
    "请输入或选择模型文件": "text357",
    "选择模型文件": "text358",
    "选择显卡, 多卡用户请使用空格分隔GPU ID": "text365",
    "验证集读取线程数, 0为自动": "text366",
    "选择验证集音频格式": "text367",
    "开始验证": "text369",
    "训练集制作指南": "text370",
    "Step 1: 数据集制作": "text371",
    "请**任选下面四种类型之一**制作数据集文件夹, 并按照给出的目录层级放置你的训练数据。完成后, 记录你的数据集**文件夹路径**以及你选择的**数据集类型**, 以便后续使用。": "text372",
    "不同的文件夹。每个文件夹包含所需的所有stems, 格式为stem_name.wav。与MUSDBHQ18数据集相同。在最新的代码版本中, 可以使用flac替代wav。<br>例如: ": "text373",
    "每个文件夹是stem_name。文件夹中包含仅由所需stem组成的wav文件。<br>例如: ": "text374",
    "可以提供以下结构的CSV文件 (或CSV文件列表) <br>例如: ": "text375",
    "与类型1相同, 但在训练过程中所有乐器都将来自歌曲的相同位置。<br>例如: ": "text376",
    "Step 2: 验证集制作": "text377",
    "验证集制作。验证数据集**必须**与上面数据集制作的Type 1(MUSDB)数据集**结构相同** (**无论你使用哪种类型的数据集进行训练**) , 此外每个文件夹还必须包含每首歌的mixture.wav, mixture.wav是所有stem的总和<br>例如: ": "text378",
    "Step 3: 选择并修改修改配置文件": "text379",
    "请先明确你想要训练的模型类型, 然后选择对应的配置文件进行修改。<br>目前有以下几种模型类型: ": "text380",
    "<br>确定好模型类型后, 你可以前往整合包根目录中的configs_template文件夹下找到对应的配置文件模板。复制一份模板, 然后根据你的需求进行修改。修改完成后记下你的配置文件路径, 以便后续使用。<br>特别说明: config_musdb18_xxx.yaml是针对MUSDB18数据集的配置文件。<br>": "text381",
    "打开配置文件模板文件夹": "text382",
    "你可以使用下表根据你的GPU选择用于训练的BS_Roformer模型的batch_size参数。表中提供的批量大小值适用于单个GPU。如果你有多个GPU, 则需要将该值乘以GPU的数量。": "text383",
    "Step 4: 数据增强": "text384",
    "数据增强可以动态更改stem, 通过从旧样本创建新样本来增加数据集的大小。现在, 数据增强的控制在配置文件中进行。下面是一个包含所有可用数据增强的完整配置示例。你可以将其复制到你的配置文件中以使用数据增强。<br>注意:<br>1. 要完全禁用所有数据增强, 可以从配置文件中删除augmentations部分或将enable设置为false。<br>2. 如果要禁用某些数据增强, 只需将其设置为0。<br>3. all部分中的数据增强应用于所有stem。<br>4. vocals/bass等部分中的数据增强仅应用于相应的stem。你可以为training.instruments中给出的所有stem创建这样的部分。": "text385",
    "设置": "text386",
    "GPU信息": "text387",
    "系统信息": "text388",
    "选择UVR模型目录": "text389",
    "保存UVR设置": "text391",
    "重置UVR设置": "text392",
    "恢复": "text394",
    "备份预设流程": "text395",
    "打开备份文件夹": "text396",
    "检查更新": "text400",
    ", 请点击检查更新按钮": "text399",
    "设置WebUI端口, 0为自动": "text401",
    "设置端口(需重启)": "text402",
    "前往Github Releases瞅一眼": "text403",
    "重置WebUI路径记录": "text404",
    "### 设置说明": "text406",
    "### 1. 选择UVR模型目录": "text407",
    "如果你的电脑中有安装UVR5, 你不必重新下载一遍UVR5模型, 只需在下方“选择UVR模型目录”中选择你的UVR5模型目录, 定位到models/VR_Models文件夹。<br>例如: E:/Program Files/Ultimate Vocal Remover/models/VR_Models 点击保存设置或重置设置后, 需要重启WebUI以更新。": "text408",
    "### 2. 预设流程设置": "text409",
    "可以将你制作的预设流程备份至backup文件夹, 也可以从backup文件夹中恢复预设流程。恢复预设流程后, 需要重启WebUI以更新。": "text410",
    "### 3. 检查更新": "text411",
    "从Github检查更新, 需要一定的网络要求。点击检查更新按钮后, 会自动检查是否有最新版本。你可以前往此整合包的下载链接或访问Github仓库下载最新版本。": "text412",
    "### 4. 重置WebUI路径记录": "text413",
    "将所有输入输出目录重置为默认路径, 预设/模型/配置文件以及上面的设置等**不会重置**, 无需担心。重置WebUI设置后, 需要重启WebUI。": "text414",
    "### 5. 重启WebUI": "text415",
    "点击 “重启WebUI” 按钮后, 会短暂性的失去连接, 随后会自动开启一个新网页。": "text416"
}